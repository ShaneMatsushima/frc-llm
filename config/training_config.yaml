# Model parameters
model_name: "gpt2-medium"
max_length: 512
special_tokens: ["<alliance>", "<autonomous>", "<teleop>", "<endgame>"]

# Training parameters
output_dir: "./models/trained/frc_assistant"
num_epochs: 5
batch_size: 4
learning_rate: 3e-5
weight_decay: 0.01
warmup_steps: 500
save_steps: 1000

# Data parameters
train_split: 0.9
val_split: 0.1
test_split: 0.1